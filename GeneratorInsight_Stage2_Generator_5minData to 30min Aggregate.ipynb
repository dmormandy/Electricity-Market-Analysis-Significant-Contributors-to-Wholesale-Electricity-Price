{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Main Contributers to Electricity RRP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Data Processing to produce Dataset of 30 min Average of 5min Generator Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "# I've included a handful of libraries here that might be useful\n",
    "import glob\n",
    "import os, zipfile, shutil\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import display # Used to display multiple pandas tables in one cell\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCADA Data for Generator Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source Data is AEMO Dispatch Data from http://www.nemweb.com.au/REPORTS/ARCHIVE/Dispatch_SCADA/. \n",
    "One month at a time was analysed for this project.\n",
    "\n",
    "This file contains actual generation data for each scheduled generation unit, semi-scheduled generation unit, and non-scheduled generating units or non-scheduled generating systems (a non-scheduled generating system comprising non-scheduled generating units). This file also contains actual load for each scheduled load. The actual generation and load data in the file is reported under a column headed 'SCADAVALUE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from_dir = 'F:\\\\RMIT_MasterofAnalytics\\\\LEP_DataScience\\\\Assignments\\\\Datasets\\\\DISPATCHSCADA'\n",
    "to_dir = 'F:\\\\RMIT_MasterofAnalytics\\\\LEP_DataScience\\\\Assignments\\\\Datasets\\\\DispatchScada_5minFiles'\n",
    "extension = \".zip\"\n",
    "\n",
    "os.chdir(from_dir) # change directory from working dir to dir with files\n",
    "\n",
    "for item in os.listdir(from_dir): # loop through items in dir\n",
    "    if item.endswith(extension): # check for \".zip\" extension\n",
    "        file_name = os.path.abspath(item) # get full path of files\n",
    "        zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "        zip_ref.extractall(to_dir) # extract file to dir\n",
    "        zip_ref.close() # close file\n",
    "        os.remove(file_name) # delete zipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from_dir = 'F:\\\\RMIT_MasterofAnalytics\\\\LEP_DataScience\\\\Assignments\\\\Datasets\\\\DispatchScada_5minFiles'\n",
    "to_dir = 'F:\\\\RMIT_MasterofAnalytics\\\\LEP_DataScience\\\\Assignments\\\\Datasets\\\\DispatchScada_5minFilesUnzipped'\n",
    "extension = \".zip\"\n",
    "\n",
    "os.chdir(from_dir) # change directory from working dir to dir with files\n",
    "\n",
    "for item in os.listdir(from_dir): # loop through items in dir\n",
    "    if item.endswith(extension): # check for \".zip\" extension\n",
    "        file_name = os.path.abspath(item) # get full path of files\n",
    "        zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "        zip_ref.extractall(to_dir) # extract file to dir\n",
    "        zip_ref.close() # close file\n",
    "        os.remove(file_name) # delete zipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysisPath = 'F:/RMIT_MasterofAnalytics/LEP_DataScience/Assignments/Datasets/DispatchScada_5minFilesUnzipped/'\n",
    "count = len([f for f in os.listdir(analysisPath) if os.path.isfile(os.path.join(analysisPath, f))])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change this if necessary\n",
    "numfiles = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the path to the data files - change this to where you store your files\n",
    "analysisPath = 'F:/RMIT_MasterofAnalytics/LEP_DataScience/Assignments/Datasets/DispatchScada_5minFilesUnzipped/'\n",
    "destinationPath = 'F:/RMIT_MasterofAnalytics/LEP_DataScience/Assignments/Datasets/DispatchScada_5minFilesProcessed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process files in 1000 blocks\n",
    "count = 0\n",
    "df_temp = pd.DataFrame()\n",
    "for file in os.listdir(analysisPath):\n",
    "    if (count < 1000):  \n",
    "        if file.endswith(\".CSV\"):\n",
    "            count = count + 1\n",
    "            if count % 100 == 0:\n",
    "                print(count)\n",
    "            input_file = os.path.join(analysisPath, file)\n",
    "            dest_file = os.path.join(destinationPath, file)\n",
    "            # Read the csv files into dataframes\n",
    "            df_input = pd.read_csv(input_file,sep=',',skiprows=1,error_bad_lines=False,warn_bad_lines=False)\n",
    "            # Move file once processed\n",
    "            shutil.move(input_file, dest_file)\n",
    "            df_temp = pd.concat([df_temp, df_input], axis=0)\n",
    "            df_temp['SETTLEMENTDATE'] = pd.to_datetime(df_temp['SETTLEMENTDATE'])\n",
    "            \n",
    "numfiles = numfiles + 1\n",
    "outputfile = 'F:/RMIT_MasterofAnalytics/LEP_DataScience/Assignments/Datasets/DispatchScada_5minDataFrame/Nov16/DispatchScada_5minNov17_' + str(numfiles) + '.csv'\n",
    "http://localhost:8889/notebooks/IPython%20Notebooks/LEP_Assignment/GeneratorInsight_Stage2_Generator%26Interconnector_5minData%20to%2030min%20Aggregate.ipynb#df_temp.to_csv(outputfile,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "analysisPath = 'F:/RMIT_MasterofAnalytics/LEP_DataScience/Assignments/Datasets/DispatchScada_5minDataFrame/Nov16/'\n",
    "count = len([f for f in os.listdir(analysisPath) if os.path.isfile(os.path.join(analysisPath, f))])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame()\n",
    "for file in os.listdir(analysisPath):\n",
    "    if file.endswith(\".csv\"):\n",
    "        input_file = os.path.join(analysisPath, file)\n",
    "        # Read the csv files into dataframes\n",
    "        df_input = pd.read_csv(input_file,sep=',',skiprows=0,error_bad_lines=False,warn_bad_lines=False)\n",
    "        df_final = pd.concat([df_final, df_input], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2341654, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>DISPATCH</th>\n",
       "      <th>UNIT_SCADA</th>\n",
       "      <th>1</th>\n",
       "      <th>SETTLEMENTDATE</th>\n",
       "      <th>DUID</th>\n",
       "      <th>SCADAVALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>DISPATCH</td>\n",
       "      <td>UNIT_SCADA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-11-01 00:10:00</td>\n",
       "      <td>BUTLERSG</td>\n",
       "      <td>8.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>DISPATCH</td>\n",
       "      <td>UNIT_SCADA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-11-01 00:10:00</td>\n",
       "      <td>CALL_A_4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>DISPATCH</td>\n",
       "      <td>UNIT_SCADA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-11-01 00:10:00</td>\n",
       "      <td>CAPTL_WF</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>DISPATCH</td>\n",
       "      <td>UNIT_SCADA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-11-01 00:10:00</td>\n",
       "      <td>CATHROCK</td>\n",
       "      <td>30.649998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I  DISPATCH  UNIT_SCADA    1       SETTLEMENTDATE      DUID  SCADAVALUE\n",
       "0  D  DISPATCH  UNIT_SCADA  1.0  2016-11-01 00:10:00  BUTLERSG    8.599998\n",
       "1  D  DISPATCH  UNIT_SCADA  1.0  2016-11-01 00:10:00  CALL_A_4    0.000000\n",
       "2  D  DISPATCH  UNIT_SCADA  1.0  2016-11-01 00:10:00  CAPTL_WF    0.000000\n",
       "3  D  DISPATCH  UNIT_SCADA  1.0  2016-11-01 00:10:00  CATHROCK   30.649998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display contents\n",
    "display(df_final.shape)\n",
    "display(df_final.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final['SETTLEMENTDATE'] = pd.to_datetime(df_final['SETTLEMENTDATE'], errors='coerce')\n",
    "df_final = df_final.dropna(subset=['SETTLEMENTDATE'])\n",
    "df_final['SETTLEMENTDATE'] = df_final['SETTLEMENTDATE'] - timedelta(minutes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    9\n",
      "1    9\n",
      "2    9\n",
      "3    9\n",
      "4    9\n",
      "Name: MINUTE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_final['DATE'] = df_final['SETTLEMENTDATE'].dt.date\n",
    "df_final['HOUR'] = df_final['SETTLEMENTDATE'].dt.hour\n",
    "df_final['MINUTE'] = df_final['SETTLEMENTDATE'].dt.minute\n",
    "print(df_final['MINUTE'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final.drop(['I','DISPATCH','UNIT_SCADA','1','SETTLEMENTDATE'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DUID  SCADAVALUE        DATE  HOUR  MINUTE\n",
      "0  BUTLERSG    8.599998  2016-11-01     0       9\n",
      "1  CALL_A_4    0.000000  2016-11-01     0       9\n",
      "2  CAPTL_WF    0.000000  2016-11-01     0       9\n",
      "3  CATHROCK   30.649998  2016-11-01     0       9\n",
      "4  CHALLHWF   22.000000  2016-11-01     0       9\n"
     ]
    }
   ],
   "source": [
    "print(df_final.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask1 = (df_final['MINUTE'] >  0.0 ) & (df_final['MINUTE'] <=  30.0 )\n",
    "mask2 = (df_final['MINUTE'] >  30.0 ) & (df_final['MINUTE'] <=  59.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            DUID  SCADAVALUE        DATE  HOUR  MINUTE\n",
      "176199  YARWUN_1   129.09999  2016-12-01     0       4\n",
      "176200     YWPS1   379.44809  2016-12-01     0       4\n",
      "176201     YWPS2   349.87341  2016-12-01     0       4\n",
      "176202     YWPS3   385.35822  2016-12-01     0       4\n",
      "176203     YWPS4     0.00000  2016-12-01     0       4\n",
      "            DUID  SCADAVALUE        DATE  HOUR  MINUTE\n",
      "175928  YARWUN_1   129.39999  2016-11-30    23      59\n",
      "175929     YWPS1   379.44809  2016-11-30    23      59\n",
      "175930     YWPS2   349.37216  2016-11-30    23      59\n",
      "175931     YWPS3   383.66455  2016-11-30    23      59\n",
      "175932     YWPS4     0.00000  2016-11-30    23      59\n"
     ]
    }
   ],
   "source": [
    "df_Group1 = df_final.loc[mask1]\n",
    "df_Group2 = df_final.loc[mask2]\n",
    "print(df_Group1.tail(5))\n",
    "print(df_Group2.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DUID  HOUR        DATE  SCADAVALUE  MINUTE\n",
      "194273  YWPS4    23  2016-11-26         0.0    30.0\n",
      "194274  YWPS4    23  2016-11-27         0.0    30.0\n",
      "194275  YWPS4    23  2016-11-28         0.0    30.0\n",
      "194276  YWPS4    23  2016-11-29         0.0    30.0\n",
      "194277  YWPS4    23  2016-11-30         0.0    30.0\n"
     ]
    }
   ],
   "source": [
    "df_30min_Group1 = df_final.loc[mask1].groupby(['DUID','HOUR','DATE'],as_index=False)['SCADAVALUE'].mean()\n",
    "df_30min_Group1['MINUTE'] = 30.0\n",
    "print(df_30min_Group1.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DUID  HOUR        DATE  SCADAVALUE  MINUTE\n",
      "194006  YWPS4    23  2016-11-26         0.0    59.0\n",
      "194007  YWPS4    23  2016-11-27         0.0    59.0\n",
      "194008  YWPS4    23  2016-11-28         0.0    59.0\n",
      "194009  YWPS4    23  2016-11-29         0.0    59.0\n",
      "194010  YWPS4    23  2016-11-30         0.0    59.0\n"
     ]
    }
   ],
   "source": [
    "df_30min_Group2 = df_final.loc[mask2].groupby(['DUID','HOUR','DATE'],as_index=False)['SCADAVALUE'].mean()\n",
    "df_30min_Group2['MINUTE'] = 59.0\n",
    "print(df_30min_Group2.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_30min = pd.concat([df_30min_Group1, df_30min_Group2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DUID  HOUR        DATE  SCADAVALUE  MINUTE\n",
      "194006  YWPS4    23  2016-11-26         0.0    59.0\n",
      "194007  YWPS4    23  2016-11-27         0.0    59.0\n",
      "194008  YWPS4    23  2016-11-28         0.0    59.0\n",
      "194009  YWPS4    23  2016-11-29         0.0    59.0\n",
      "194010  YWPS4    23  2016-11-30         0.0    59.0\n"
     ]
    }
   ],
   "source": [
    "print(df_30min.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count         388289\n",
      "unique            31\n",
      "top       2016-11-26\n",
      "freq           12960\n",
      "Name: DATE, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_30min['DATE'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_30min['DATE'] = df_30min['DATE'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_30min['DATETIME'] = df_30min['DATE'] + pd.to_timedelta(df_30min['HOUR'], unit='h') + pd.to_timedelta(df_30min['MINUTE'], unit='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DUID  HOUR       DATE  SCADAVALUE  MINUTE            DATETIME\n",
      "194006  YWPS4    23 2016-11-26         0.0    59.0 2016-11-26 23:59:00\n",
      "194007  YWPS4    23 2016-11-27         0.0    59.0 2016-11-27 23:59:00\n",
      "194008  YWPS4    23 2016-11-28         0.0    59.0 2016-11-28 23:59:00\n",
      "194009  YWPS4    23 2016-11-29         0.0    59.0 2016-11-29 23:59:00\n",
      "194010  YWPS4    23 2016-11-30         0.0    59.0 2016-11-30 23:59:00\n"
     ]
    }
   ],
   "source": [
    "print(df_30min.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Need to add one minute to times with minute = 59\n",
    "mask = (df_30min['MINUTE']==59.0)\n",
    "df_30min.loc[mask,'DATETIME']= df_30min.loc[mask,'DATETIME'] + timedelta(minutes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DUID  HOUR       DATE  SCADAVALUE  MINUTE   DATETIME\n",
      "194006  YWPS4    23 2016-11-26         0.0    59.0 2016-11-27\n",
      "194007  YWPS4    23 2016-11-27         0.0    59.0 2016-11-28\n",
      "194008  YWPS4    23 2016-11-28         0.0    59.0 2016-11-29\n",
      "194009  YWPS4    23 2016-11-29         0.0    59.0 2016-11-30\n",
      "194010  YWPS4    23 2016-11-30         0.0    59.0 2016-12-01\n"
     ]
    }
   ],
   "source": [
    "print(df_30min.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Need to add one minute to times with minute = 59\n",
    "mask = (df_30min['MINUTE']==59.0)\n",
    "df_30min.loc[mask,'MINUTE']= 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DUID  HOUR       DATE  SCADAVALUE  MINUTE   DATETIME\n",
      "194006  YWPS4    23 2016-11-26         0.0     0.0 2016-11-27\n",
      "194007  YWPS4    23 2016-11-27         0.0     0.0 2016-11-28\n",
      "194008  YWPS4    23 2016-11-28         0.0     0.0 2016-11-29\n",
      "194009  YWPS4    23 2016-11-29         0.0     0.0 2016-11-30\n",
      "194010  YWPS4    23 2016-11-30         0.0     0.0 2016-12-01\n"
     ]
    }
   ],
   "source": [
    "print(df_30min.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_30min.drop(['DATE','HOUR','MINUTE'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DUID  SCADAVALUE   DATETIME\n",
      "194006  YWPS4         0.0 2016-11-27\n",
      "194007  YWPS4         0.0 2016-11-28\n",
      "194008  YWPS4         0.0 2016-11-29\n",
      "194009  YWPS4         0.0 2016-11-30\n",
      "194010  YWPS4         0.0 2016-12-01\n"
     ]
    }
   ],
   "source": [
    "print(df_30min.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     DUID  SCADAVALUE            DATETIME\n",
      "0  AGLHAL    0.000000 2016-11-01 00:30:00\n",
      "1  AGLHAL    0.000000 2016-11-02 00:30:00\n",
      "2  AGLHAL    3.364665 2016-11-03 00:30:00\n",
      "3  AGLHAL    0.000000 2016-11-04 00:30:00\n",
      "4  AGLHAL    0.000000 2016-11-05 00:30:00\n"
     ]
    }
   ],
   "source": [
    "print(df_30min.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_output = df_30min.pivot(index='DATETIME', columns='DUID', values='SCADAVALUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_output['DATETIME'] = df_output.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUID                 AGLHAL  AGLSOM  ANGAST1      ARWF1   BALDHWF1  BARCALDN  \\\n",
      "DATETIME                                                                       \n",
      "2016-11-01 00:30:00     0.0     0.0      0.0  17.540000  41.548000       0.0   \n",
      "2016-11-01 01:00:00     0.0     0.0      0.0   8.316667  49.845167       0.0   \n",
      "2016-11-01 01:30:00     0.0     0.0      0.0   8.783333  59.467667       0.0   \n",
      "2016-11-01 02:00:00     0.0     0.0      0.0  10.416667  74.911500       0.0   \n",
      "2016-11-01 02:30:00     0.0     0.0      0.0   8.516667  72.100167       0.0   \n",
      "\n",
      "DUID                 BARRON-1  BARRON-2    BASTYAN  BBTHREE1  \\\n",
      "DATETIME                                                       \n",
      "2016-11-01 00:30:00       0.0       0.0  78.992006       0.0   \n",
      "2016-11-01 01:00:00       0.0       0.0  79.018338       0.0   \n",
      "2016-11-01 01:30:00       0.0       0.0  79.021672       0.0   \n",
      "2016-11-01 02:00:00       0.0       0.0  79.165007       0.0   \n",
      "2016-11-01 02:30:00       0.0       0.0  79.253340       0.0   \n",
      "\n",
      "DUID                        ...               WPWF  YABULU  YABULU2  \\\n",
      "DATETIME                    ...                                       \n",
      "2016-11-01 00:30:00         ...          15.600000     0.0      0.0   \n",
      "2016-11-01 01:00:00         ...          17.166667     0.0      0.0   \n",
      "2016-11-01 01:30:00         ...          13.833333     0.0      0.0   \n",
      "2016-11-01 02:00:00         ...           6.500000     0.0      0.0   \n",
      "2016-11-01 02:30:00         ...           5.833333     0.0      0.0   \n",
      "\n",
      "DUID                  YAMBUKWF    YARWUN_1  YWPS1       YWPS2       YWPS3  \\\n",
      "DATETIME                                                                    \n",
      "2016-11-01 00:30:00  13.700000  114.765998    0.0  327.166076  347.702284   \n",
      "2016-11-01 01:00:00  12.850000  114.628332    0.0  302.127848  340.381857   \n",
      "2016-11-01 01:30:00  13.283333  114.409998    0.0  301.083540  338.735228   \n",
      "2016-11-01 02:00:00  12.466667  115.233332    0.0  300.248108  336.288830   \n",
      "2016-11-01 02:30:00  11.450000  114.091665    0.0  299.370885  332.995568   \n",
      "\n",
      "DUID                      YWPS4            DATETIME  \n",
      "DATETIME                                             \n",
      "2016-11-01 00:30:00  348.323296 2016-11-01 00:30:00  \n",
      "2016-11-01 01:00:00  338.782278 2016-11-01 01:00:00  \n",
      "2016-11-01 01:30:00  338.641138 2016-11-01 01:30:00  \n",
      "2016-11-01 02:00:00  326.267928 2016-11-01 02:00:00  \n",
      "2016-11-01 02:30:00  318.928692 2016-11-01 02:30:00  \n",
      "\n",
      "[5 rows x 271 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_output.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1441, 271)\n"
     ]
    }
   ],
   "source": [
    "print(df_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputfile='F:/RMIT_MasterofAnalytics/LEP_DataScience/Assignments/Datasets/DispatchScada_Nov16_30minAverage.csv'\n",
    "df_output.to_csv(outputfile,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
